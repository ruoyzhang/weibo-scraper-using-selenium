{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weibo_scrapper import weibo_scrapper\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_date = datetime.datetime.strptime('17-04-2016', '%d-%m-%Y')\n",
    "end_date = datetime.datetime.strptime('17-10-2016', '%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the variables used for testing\n",
    "username = 'ruoyzhang@outlook.com'\n",
    "password = 'Cyfloel1.1.'\n",
    "search_keyword = '人工智能'\n",
    "save_dir = '../master_thesis_data/weibo'\n",
    "max_page = 15\n",
    "num_days = (end_date - starting_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_this = weibo_scrapper(username=username, password=password,\n",
    "                            save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 'https://www.weibo.com/login.php'\n",
      "inputting username and password\n",
      "login successful\n",
      "End of login\n"
     ]
    }
   ],
   "source": [
    "scrape_this.login_weibo()\n",
    "time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "navigating to Weibo adv search page\n",
      "waiting for page to load ...\n",
      "specifying search criterion\n",
      "waiting for results to load ...\n",
      "there are  15  of results, the scraper will aquire tweets of the first 15 pages\n",
      "now scrapping ...\n",
      "page  1  complete\n",
      "page  2  complete\n",
      "page  3  complete\n",
      "page  4  complete\n",
      "page  5  complete\n",
      "page  6  complete\n",
      "page  7  complete\n",
      "page  8  complete\n",
      "page  9  complete\n",
      "page  10  complete\n",
      "page  11  complete\n",
      "page  12  complete\n",
      "page  13  complete\n",
      "page  14  complete\n",
      "page  15  complete\n",
      "all pages scrapped, now saving ...\n",
      "save complete, files can be found at:  ../master_thesis_data/weibo\n",
      "time lapsed for 1 iterations is 152.81301617622375 seconds\n",
      "average time per iteration is: 152.81301021575928 seconds\n",
      "navigating to Weibo adv search page\n",
      "waiting for page to load ...\n",
      "specifying search criterion\n",
      "waiting for results to load ...\n",
      "there are  15  of results, the scraper will aquire tweets of the first 15 pages\n",
      "now scrapping ...\n",
      "page  1  complete\n",
      "page  2  complete\n",
      "page  3  complete\n",
      "page  4  complete\n",
      "page  5  complete\n",
      "page  6  complete\n",
      "page  7  complete\n",
      "page  8  complete\n",
      "page  9  complete\n",
      "page  10  complete\n",
      "page  11  complete\n",
      "page  12  complete\n",
      "page  13  complete\n",
      "page  14  complete\n",
      "page  15  complete\n",
      "all pages scrapped, now saving ...\n",
      "save complete, files can be found at:  ../master_thesis_data/weibo\n",
      "time lapsed for 2 iterations is 286.24846625328064 seconds\n",
      "average time per iteration is: 143.1242311000824 seconds\n",
      "navigating to Weibo adv search page\n",
      "waiting for page to load ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-050207eb177e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     scrape_this.scrape(begin_date=date, end_date=date,\n\u001b[1;32m      7\u001b[0m                       \u001b[0msearch_keyword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_keyword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                       max_page=max_page)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mavg_time_so_far\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time lapsed for'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iterations is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PythonWorkingDirectory/Master_thesis_scrapping/weibo_scrapper.py\u001b[0m in \u001b[0;36mscrape\u001b[0;34m(self, begin_date, end_date, search_keyword, max_page)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;31m# need to wait for the page to load else it won't work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'specifying search criterion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "begin = time.time()\n",
    "for i in range(num_days):\n",
    "    date = starting_date + datetime.timedelta(days = i)\n",
    "    date = \"-\".join([str(int(elem)) for elem in str(starting_date.date()).split('-')])\n",
    "    scrape_this.scrape(begin_date=date, end_date=date,\n",
    "                      search_keyword=search_keyword,\n",
    "                      max_page=max_page)\n",
    "    avg_time_so_far = (time.time() - begin)/(i+1)\n",
    "    print('time lapsed for', str(i+1), 'iterations is', str(time.time()-begin), 'seconds')\n",
    "    print('average time per iteration is:', avg_time_so_far,'seconds')\n",
    "    print('total time to lapse predicted to be', str((avg_time_so_far * (num_days))/60), 'minutes')\n",
    "    print('time remaining estimated to be', str((avg_time_so_far * (num_days-i-1))/60), 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-4-17'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"-\".join([str(int(elem)) for elem in str(starting_date.date()).split('-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
